{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNEBqnN40wFm/Q63U9IdHDk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rslab-ntua/MSc_GBDA/blob/master/2024_Lab1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intro to Pytorch!"
      ],
      "metadata": {
        "id": "XMhxX1ggX1s-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch  # Import PyTorch!\n",
        "import numpy as np\n",
        "\n",
        "# Define a NumPy array\n",
        "A = np.array([[1.2, 2.4], [3.6, 4.8]])\n",
        "print(\"This is a NumPy array:\\n\", A, \"\\nIt's a collection of numbers organized in a grid with 2 rows and 2 columns.\")\n",
        "\n",
        "# Convert NumPy array to a PyTorch tensor\n",
        "B = torch.from_numpy(A)\n",
        "print(\"\\n\\nThis is a PyTorch tensor:\\n\", B, \"\\nIt's like a NumPy array, but designed to work efficiently with PyTorch.\")\n",
        "\n",
        "# Demonstrate similarities between NumPy and PyTorch operations\n",
        "print(\"NumPy operations:\", A.shape, A.dtype, A.mean(), A.max(), \"\\nThese are basic operations like shape, data type, mean, and maximum value.\")\n",
        "print(\"PyTorch operations:\", B.shape, B.dtype, B.mean(), B.max(), \"\\nThe PyTorch tensor behaves similarly to the NumPy array in terms of operations.\")\n",
        "\n",
        "# Get a NumPy object from a PyTorch tensor\n",
        "A2 = B.numpy()\n",
        "print(\"NumPy object from PyTorch:\\n\", A2, \"\\nYou can convert a PyTorch tensor back to a NumPy array whenever needed.\")\n",
        "\n",
        "# Create new tensors using different methods\n",
        "C1 = torch.ones((3, 4))  # Create a tensor filled with ones\n",
        "print(\"Tensor C1 filled with ones:\\n\", C1, \"\\nIt's a 3x4 grid filled with the value 1.\")\n",
        "\n",
        "C2 = torch.zeros_like(C1)  # Create a tensor filled with zeros, with the same size and dtype as C1\n",
        "C3 = torch.rand((2,))  # Create a random tensor of size 2\n",
        "print(\"Tensor C3 with random values:\\n\", C3, \"\\nIt's a 1-dimensional tensor containing random numbers.\")\n",
        "\n",
        "data = [[1, 3, 5], [2, 4, 6]]\n",
        "C4 = torch.tensor(data)  # Create a tensor from a list (dtype inferred)\n",
        "C5 = torch.Tensor(data)  # Create a tensor from a list (dtype float32)\n",
        "C6 = torch.as_tensor(data)  # Create a tensor from a list (dtype inferred)\n",
        "print(\"Tensor C4 created from a list (dtype inferred):\\n\", C4, C4.shape, C4.dtype)\n",
        "print(\"Tensor C5 created from a list:\\n\", C5, C5.shape, C5.dtype)\n",
        "print(\"Tensor C6 created from a list (dtype inferred):\\n\", C6, C6.shape, C6.dtype)\n",
        "\n",
        "# Comparing tensors\n",
        "print(\"Are C4 and C5 equal element-wise?\", C4 == C5, \"\\nYou can compare tensors element-wise.\")\n",
        "print(\"Are all elements of C4 and C5 equal?\", (C4 == C5).all(), \"\\nYou can check if all elements of two tensors are equal.\")\n",
        "\n",
        "# Slicing, indexing, and modifying tensors\n",
        "print(\"Original tensor C4:\\n\", C4)\n",
        "C4[0, 1] = 32  # Modify a specific element\n",
        "C4[-1, -2] = 64\n",
        "print(\"Modified tensor C4:\\n\", C4, \"\\nYou can access, modify, and slice tensors just like NumPy arrays.\")\n",
        "\n",
        "# Accessing specific parts of the tensor\n",
        "print(\"First row of C4:\", C4[0], \"\\nYou can access specific rows or columns of a tensor.\")\n",
        "print(\"Last 2 columns of C4:\\n\", C4[:, 1:], \"\\nYou can slice tensors to extract specific parts.\")\n",
        "\n",
        "# Arithmetic operations on tensors\n",
        "D = 2.5 * torch.ones_like(C1) + 4  # Arithmetic operations on tensors\n",
        "print(\"Tensor D with arithmetic operations:\\n\", D, \"\\nYou can perform arithmetic operations on tensors.\")\n",
        "\n",
        "D2 = D / 2\n",
        "print(\"Tensor D2 obtained by dividing D by 2:\\n\", D2)\n",
        "\n",
        "# Matrix multiplication\n",
        "M1 = torch.rand((2, 4))\n",
        "M2 = torch.rand((4, 1))\n",
        "\n",
        "MM = M1 @ M2  # Matrix multiplication\n",
        "print(\"Result of matrix multiplication:\", MM.shape, \"\\nYou can perform matrix multiplication with tensors.\")\n",
        "\n",
        "# Data reshape\n",
        "K = torch.arange(9)\n",
        "print(\"A 9-vector:\", K)\n",
        "K2 = K.reshape(3, 3)  # Reshape the vector to a 3x3 matrix\n",
        "print(\"Reshaped to a 3x3 matrix:\\n\", K2, \"\\nYou can reshape tensors to different dimensions.\")\n",
        "\n",
        "K2_transpose = K2.T  # Transpose the matrix\n",
        "print(\"Transposed matrix:\\n\", K2_transpose)\n",
        "\n",
        "# Device placement\n",
        "if torch.cuda.is_available():\n",
        "    print(\"Device of tensor D:\", D.device, \"\\nYou can check on which device (CPU or GPU) a tensor resides.\")\n",
        "    print(\"Is CUDA available?\", torch.cuda.is_available())\n",
        "    D_gpu = D.to(\"cuda\")  # Move tensor to GPU\n",
        "    print(\"Device of tensor D_gpu:\", D_gpu.device, \"\\nYou can move tensors between CPU and GPU for parallel computation.\")\n",
        "    D_cpu = D_gpu.cpu()  # Move tensor back to CPU\n",
        "    print(\"Tensor D_cpu on CPU with numpy representation:\\n\", D_cpu.numpy(), D_cpu.device)\n"
      ],
      "metadata": {
        "id": "wNLWHXoyjQ0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A Simple Perceptron"
      ],
      "metadata": {
        "id": "46V6tcuiashU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class Perceptron(nn.Module):\n",
        "    def __init__(self, features_in) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        # Initialize weights and bias randomly\n",
        "        self.W = torch.rand((features_in, ))\n",
        "        self.b = torch.rand((1, ))\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # Compute the weighted sum and add the bias\n",
        "        val = torch.dot(self.W, x) + self.b\n",
        "\n",
        "        # Apply sigmoid activation function\n",
        "        return torch.sigmoid(val)\n",
        "\n",
        "# Create an instance of the Perceptron model with 3 input features\n",
        "perceptron = Perceptron(features_in=3)\n",
        "\n",
        "# Print the architecture of the perceptron\n",
        "print(\"Perceptron architecture:\")\n",
        "print(\"Weights:\\n\", perceptron.W, \"\\nBias:\\n\", perceptron.b)\n",
        "\n",
        "# Create a sample tensor to pass through the perceptron\n",
        "my_sample = torch.tensor([2, 3, 4]).type(torch.float32)\n",
        "\n",
        "# Print the input vector\n",
        "print(\"\\nInput vector:\")\n",
        "print(my_sample)\n",
        "\n",
        "# Forward pass the sample through the perceptron and print the output\n",
        "out = perceptron(x=my_sample)\n",
        "print(\"\\nOutput of the perceptron:\")\n",
        "print(out)\n",
        "\n"
      ],
      "metadata": {
        "id": "P2ei7eH8YGYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "\n",
        "# Print description of the dataset\n",
        "# print(\"Iris dataset description:\")\n",
        "# print(iris.DESCR)\n",
        "\n",
        "# Print feature names\n",
        "print(\"\\nFeature names:\")\n",
        "print(iris.feature_names)\n",
        "\n",
        "# Print target names\n",
        "print(\"\\nTarget names:\")\n",
        "print(iris.target_names)\n",
        "\n",
        "# Filter the data for Iris-versicolor and Iris-setosa\n",
        "versicolor_data = iris.data[iris.target == 1]\n",
        "setosa_data = iris.data[iris.target == 0]\n",
        "\n",
        "# Print the number of samples for each class\n",
        "print(\"Number of samples for Iris-versicolor:\", len(versicolor_data))\n",
        "print(\"Number of samples for Iris-setosa:\", len(setosa_data))\n",
        "\n",
        "# Filter petal_len, petal_width\n",
        "versicolor_data = versicolor_data[:, -2:]\n",
        "setosa_data = setosa_data[:, -2:]\n"
      ],
      "metadata": {
        "id": "xtKwvwtYvIvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w1 = 0.1 #@param {type:\"number\"}\n",
        "w2 = 0.2 #@param {type:\"number\"}\n",
        "b = -0.4 #@param {type:\"number\"}\n",
        "\n",
        "\n",
        "def plot_boundary(w1, w2, b, x_min, x_max, fmt=\"r\"):\n",
        "    # Define two points on the decision boundary based on the weights and bias\n",
        "    x1 = x_max\n",
        "    y1 = (-b - w1 * x1) / w2\n",
        "    x2 = x_min\n",
        "    y2 = (-b - w1 * x2) / w2\n",
        "\n",
        "    # Plot the decision boundary line\n",
        "    plt.plot([x1, x2], [y1, y2], fmt)\n",
        "\n",
        "# Create the plot\n",
        "plt.figure(figsize=(9, 6))\n",
        "\n",
        "# Plot petal width vs petal length for Iris-versicolor\n",
        "plt.scatter(versicolor_data[:, 0], versicolor_data[:, 1], color='orange', label='Iris-versicolor')\n",
        "\n",
        "# Plot petal width vs petal length for Iris-setosa\n",
        "plt.scatter(setosa_data[:, 0], setosa_data[:, 1], color='blue', label='Iris-setosa')\n",
        "\n",
        "# Plot decision boundary using provided weights and bias\n",
        "plot_boundary(w1, w2, b, x_min=0, x_max=6, fmt=\"r\")\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Petal Length (cm)', fontweight='bold')\n",
        "plt.ylabel('Petal Width (cm)', fontweight='bold')\n",
        "plt.title('Petal Width vs Petal Length', fontweight='bold')\n",
        "\n",
        "# Set axis limits\n",
        "plt.xlim((0, 6))\n",
        "plt.ylim((0, 2))\n",
        "\n",
        "# Add legend\n",
        "plt.legend()\n",
        "\n",
        "# Show plot\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "62AbwoDdxn8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import functional as F\n",
        "\n",
        "# Instantiate a Perceptron object with 2 input features\n",
        "perceptron = Perceptron(features_in=2)\n",
        "\n",
        "# Set the weights and bias of the Perceptron\n",
        "perceptron.W = torch.tensor([w1, w2]).type(torch.float32)  # Set weights\n",
        "perceptron.b = torch.tensor([b]).type(torch.float32)  # Set bias\n",
        "\n",
        "# Define a sample input\n",
        "sample = [4, 1.2]\n",
        "\n",
        "# Forward pass through the Perceptron\n",
        "out = perceptron(torch.tensor(sample))\n",
        "\n",
        "# Print the output of the Perceptron\n",
        "print(f\"Perceptron output: {float(out)}\")\n",
        "\n",
        "# Compute the binary cross-entropy (BCE) loss\n",
        "bce_val = F.binary_cross_entropy_with_logits(input=out, target=torch.ones(1))\n",
        "\n",
        "# Print the computed BCE loss\n",
        "print(f\"BCE value: {bce_val}\")\n",
        "\n",
        "# Compute the mean squared error (MSE) loss\n",
        "mse_val = F.mse_loss(input=out, target=torch.ones(1))\n",
        "\n",
        "# Print the computed MSE loss\n",
        "print(f\"MSE value: {mse_val}\")"
      ],
      "metadata": {
        "id": "eyiFEzb8FuLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP"
      ],
      "metadata": {
        "id": "GunDbB2LcZnT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a multi-layer perceptron (MLP) using nn.Sequential\n",
        "mlp = nn.Sequential(\n",
        "    nn.Linear(in_features=2, out_features=2),  # First linear layer with 2 input and 2 output features\n",
        "    nn.Tanh(),  # Tanh activation function\n",
        "    nn.Linear(in_features=2, out_features=1),  # Second linear layer with 2 input and 1 output features\n",
        "    nn.Sigmoid()  # Sigmoid activation function\n",
        ")\n",
        "\n",
        "# Print weights and biases of the first linear layer\n",
        "print(\"1st linear layer weights:\\n\", mlp[0].weight.data)  # Print weights of the first linear layer\n",
        "print(\"1st linear layer bias:\\n\", mlp[0].bias.data)  # Print bias of the first linear layer\n",
        "\n",
        "# Print weights and biases of the second linear layer\n",
        "print(\"2nd linear layer weights:\\n\", mlp[2].weight.data)  # Print weights of the second linear layer\n",
        "print(\"2nd linear layer bias:\\n\", mlp[2].bias.data)  # Print bias of the second linear layer\n"
      ],
      "metadata": {
        "id": "BANoMaJAb636"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w11 = 1 #@param {type:\"number\"}\n",
        "w12 = 1 #@param {type:\"number\"}\n",
        "b1 = -0.5 #@param {type:\"number\"}\n",
        "\n",
        "w21 = 1 #@param {type:\"number\"}\n",
        "w22 = 1 #@param {type:\"number\"}\n",
        "b2 = -1.5 #@param {type:\"number\"}\n",
        "\n",
        "\n",
        "# Define XOR data and labels\n",
        "xor_data = np.array([\n",
        "    [True, True],\n",
        "    [True, False],\n",
        "    [False, True],\n",
        "    [False, False]\n",
        "])\n",
        "\n",
        "xor_labels = np.array([False, True, True, False])\n",
        "\n",
        "# Plot XOR graph\n",
        "plt.figure(figsize=(9, 9))\n",
        "plt.grid(True)\n",
        "\n",
        "# Scatter plot for true data points\n",
        "true_data = xor_data[xor_labels]\n",
        "plt.scatter(true_data[:, 0], true_data[:, 1], color='green', label='True', marker=\"x\", s=150, linewidths=3)\n",
        "\n",
        "# Scatter plot for false data points\n",
        "false_data = xor_data[np.logical_not(xor_labels)]\n",
        "plt.scatter(false_data[:, 0], false_data[:, 1], color='red', label='False', marker=\"+\", s=150, linewidths=3)\n",
        "\n",
        "# Plot decision boundary for first neuron\n",
        "plot_boundary(w11, w12, b1, -0.3, 1.3, \"c\")\n",
        "\n",
        "# Plot decision boundary for second neuron\n",
        "plot_boundary(w21, w22, b2, -0.3, 1.3, \"m\")\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Var 1', fontweight='bold')\n",
        "plt.ylabel('Var 2', fontweight='bold')\n",
        "plt.title('XOR graph', fontweight='bold')\n",
        "\n",
        "# Set axis limits\n",
        "plt.xlim((-0.3, 1.3))\n",
        "plt.ylim((-0.3, 1.3))\n",
        "\n",
        "# Add legend\n",
        "plt.legend()\n",
        "\n",
        "# Show plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FNfo-F_FB9aa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l2_w1 = 10 #@param {type:\"number\"}\n",
        "l2_w2 = -10 #@param {type:\"number\"}\n",
        "l2_b1 = -6.6 #@param {type:\"number\"}\n",
        "\n",
        "# Set the weights and biases for the first linear layer of the MLP\n",
        "mlp[0].weight.data = torch.tensor([[w11, w21], [w12, w22]]).type(torch.float32)  # Set weights\n",
        "mlp[0].bias.data = torch.tensor([b1, b2]).type(torch.float32)  # Set bias\n",
        "\n",
        "# Perform inference and detach gradients for visualization\n",
        "intermediate_out = mlp[:2](torch.from_numpy(xor_data).type(torch.float32)).detach().numpy()\n",
        "\n",
        "# Plot the intermediate output\n",
        "plt.figure(figsize=(9, 9))\n",
        "plt.grid(True)\n",
        "\n",
        "# Scatter plot for true data points\n",
        "true_data = intermediate_out[xor_labels]\n",
        "plt.scatter(true_data[:, 0], true_data[:, 1], color='green', label='True', marker=\"x\", s=150, linewidths=3)\n",
        "\n",
        "# Scatter plot for false data points\n",
        "false_data = intermediate_out[np.logical_not(xor_labels)]\n",
        "plt.scatter(false_data[:, 0], false_data[:, 1], color='red', label='False', marker=\"+\", s=150, linewidths=3)\n",
        "\n",
        "# Plot decision boundary\n",
        "plot_boundary(l2_w1, l2_w2, l2_b1, -1, 1, \"b\")\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Var 1', fontweight='bold')\n",
        "plt.ylabel('Var 2', fontweight='bold')\n",
        "plt.title('XOR graph', fontweight='bold')\n",
        "\n",
        "# Set axis limits\n",
        "plt.xlim((-1, 1))\n",
        "plt.ylim((-1, 1))\n",
        "\n",
        "# Add legend\n",
        "plt.legend()\n",
        "\n",
        "# Show plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PWWgT4qADxXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the weights and biases for the second linear layer of the MLP\n",
        "mlp[2].weight.data = torch.tensor([l2_w1, l2_w2]).view(1, 2).type(torch.float32)  # Set weights\n",
        "mlp[2].bias.data = torch.tensor([l2_b1]).type(torch.float32)  # Set bias\n",
        "\n",
        "# Switch the model to evaluation mode\n",
        "mlp.eval()\n",
        "\n",
        "# Perform inference without gradient computation\n",
        "with torch.no_grad():\n",
        "    # Forward pass through the model with the XOR data\n",
        "    out = mlp(torch.from_numpy(xor_data).type(torch.float32)).ravel().numpy()  # Batch-inference\n",
        "\n",
        "# Print the raw predictions\n",
        "print(f\"Predictions (raw):\\n{out.tolist()}\")\n",
        "\n",
        "# Print the thresholded predictions (1 if > 0.5, else 0)\n",
        "print(f\"Predictions (thresholded):\\n{(out > 0.5).tolist()}\")\n",
        "\n",
        "# Print the ground truth labels\n",
        "print(f\"Labels:\\n{xor_labels.tolist()}\")"
      ],
      "metadata": {
        "id": "dyO5VmWPOqkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Miscellaneous"
      ],
      "metadata": {
        "id": "jxobXn4DfSny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install pystac_client and rasterio packages using pip\n",
        "!pip install pystac_client rasterio"
      ],
      "metadata": {
        "id": "anCdFwGwiCZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Access a STAC catalogue"
      ],
      "metadata": {
        "id": "zikowqARrbdq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from pystac_client import Client\n",
        "from shapely.geometry import Point\n",
        "\n",
        "# Define the API URL for STAC\n",
        "api_url = \"https://earth-search.aws.element84.com/v1\"\n",
        "\n",
        "# Open a connection to the STAC API\n",
        "client = Client.open(api_url)\n",
        "\n",
        "# Specify the collection to search for\n",
        "collection = \"sentinel-2-l2a\"  # Sentinel-2, Level 2A, Cloud Optimized GeoTiffs (COGs)\n",
        "\n",
        "# Define a point geometry (AMS coordinates)\n",
        "point = Point(22.4, 39.6)\n",
        "\n",
        "print(\"Searching for Sentinel-2 scenes intersecting with the specified point...\")\n",
        "\n",
        "# Search for items (scenes) that intersect with the defined point\n",
        "search = client.search(\n",
        "    collections=[collection],  # Search within the specified collection\n",
        "    intersects=point,  # Search for items that intersect with the point geometry\n",
        "    max_items=10,  # Maximum number of items to return\n",
        ")\n",
        "\n",
        "# Get the item collection containing the search results\n",
        "items = search.item_collection()\n",
        "\n",
        "print(\"Retrieved Sentinel-2 scenes:\")\n",
        "\n",
        "# Iterate over the retrieved items\n",
        "for item in items:\n",
        "    print(f\"Scene ID: {item.id}\")  # Print basic information about each item (scene)\n",
        "\n",
        "# Access metadata of the first item (scene) in the search results\n",
        "item = items[0]\n",
        "print(\"Metadata of the first scene:\")\n",
        "print(f\"Datetime: {item.datetime}\")  # Print the datetime of the item\n",
        "print(f\"Geometry: {item.geometry}\")  # Print the geometry (bounding box) of the item\n",
        "print(\"Additional properties:\")\n",
        "print(item.properties)  # Print additional properties of the item\n",
        "\n",
        "# Access assets (data files) associated with the first item\n",
        "assets = item.assets  # Get the asset dictionary of the first item\n",
        "\n",
        "print(\"Assets of the first scene:\")\n",
        "\n",
        "# Print keys (asset names) in the asset dictionary\n",
        "print(\"Asset names:\")\n",
        "print(assets.keys())\n",
        "\n",
        "# Iterate over assets and print their titles and URLs\n",
        "for key, asset in assets.items():\n",
        "    print(f\"{asset.title}: {asset.href}\")  # Print asset title and URL\n"
      ],
      "metadata": {
        "id": "JeCmRmlygMI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read COGs (cloud-optimized geotiffs)"
      ],
      "metadata": {
        "id": "dogtdGXnrhRe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import rasterio as rio\n",
        "from pprint import pprint\n",
        "\n",
        "# Open the blue band raster file\n",
        "with rio.open(assets[\"blue\"].href) as dset:\n",
        "    # Read the blue band data\n",
        "    B = dset.read()\n",
        "    # Get the profile (metadata) of the raster dataset\n",
        "    profile = dset.profile\n",
        "    # Print the transformation parameters (geotransform) of the raster dataset\n",
        "    print(\"Transformation parameters (geotransform):\")\n",
        "    print(dset.transform)\n",
        "    # Print the coordinate reference system (CRS) of the raster dataset\n",
        "    print(\"Coordinate reference system (CRS):\")\n",
        "    print(dset.crs)\n",
        "\n",
        "# Open the green band raster file\n",
        "with rio.open(assets[\"green\"].href) as dset:\n",
        "    # Read the green band data\n",
        "    G = dset.read()\n",
        "\n",
        "# Open the red band raster file\n",
        "with rio.open(assets[\"red\"].href) as dset:\n",
        "    # Read the red band data\n",
        "    R = dset.read()\n",
        "\n",
        "# Print the profile (metadata) of the raster dataset\n",
        "print(\"Raster dataset profile:\")\n",
        "pprint(profile)"
      ],
      "metadata": {
        "id": "wAwO8chKiAym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Print shape and data type of arrays\n",
        "print(\"Shape and data type of arrays:\")\n",
        "print(B.shape, B.dtype)  # Assuming B, G, R are defined elsewhere\n",
        "print(G.shape)\n",
        "print(R.shape)\n",
        "\n",
        "# Retrieve scale and offset for each band\n",
        "scale_red = assets[\"red\"].to_dict()['raster:bands'][0]['scale']\n",
        "offset_red = assets[\"red\"].to_dict()['raster:bands'][0]['offset']\n",
        "print(f\"Red band scale: {scale_red}, offset: {offset_red}\")\n",
        "\n",
        "scale_blue = assets[\"blue\"].to_dict()['raster:bands'][0]['scale']\n",
        "offset_blue = assets[\"blue\"].to_dict()['raster:bands'][0]['offset']\n",
        "print(f\"Blue band scale: {scale_blue}, offset: {offset_blue}\")\n",
        "\n",
        "scale_green = assets[\"green\"].to_dict()['raster:bands'][0]['scale']\n",
        "offset_green = assets[\"green\"].to_dict()['raster:bands'][0]['offset']\n",
        "print(f\"Green band scale: {scale_green}, offset: {offset_green}\")\n",
        "\n",
        "# Combine the bands to form the RGB image\n",
        "RGB = np.concatenate([\n",
        "    scale_red * R + offset_red,\n",
        "    scale_green * G + offset_green,\n",
        "    scale_blue * B + offset_blue\n",
        "], axis=0)\n",
        "\n",
        "# Delete individual band arrays to save memory\n",
        "del R\n",
        "del B\n",
        "del G\n"
      ],
      "metadata": {
        "id": "8FUlU3wija-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualization!"
      ],
      "metadata": {
        "id": "ihOGfw7KrrQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a subset of the original tile and set format to HWC from CHW\n",
        "sub_im = RGB.transpose(1,2,0)[:3000, :3000]\n",
        "\n",
        "# Create a new figure with a 1x2 grid\n",
        "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
        "\n",
        "# Plot the first image in the first subplot\n",
        "axes[0].imshow(sub_im, vmin=0, vmax=1)\n",
        "axes[0].set_title('Original Image')\n",
        "\n",
        "# Plot the second image in the second subplot\n",
        "axes[1].imshow(1.4*sub_im + 0.15, vmin=0, vmax=1)\n",
        "axes[1].set_title('Enhanced Image')\n",
        "\n",
        "# Adjust layout to avoid overlap\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "29IM-HaCkBDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save multi-band tiff to disk"
      ],
      "metadata": {
        "id": "WDdYITOArukP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import rasterio\n",
        "from rasterio.transform import from_origin\n",
        "\n",
        "# Assuming your array is named 'data'\n",
        "\n",
        "profile['count'] = RGB.shape[0]\n",
        "\n",
        "# Create the GeoTIFF file\n",
        "with rasterio.open('output.tif', 'w', **profile) as dst:\n",
        "    # Write the array data to the GeoTIFF bands\n",
        "    for i, band_data in enumerate(RGB):\n",
        "        dst.write(band_data, i+1)  # Write each band separately\n",
        "\n",
        "print(\"GeoTIFF file saved successfully.\")\n"
      ],
      "metadata": {
        "id": "tv5hcOAUnXgt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}